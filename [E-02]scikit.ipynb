{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79a1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # 데이터 분리 (train/test)\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정나무\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트\n",
    "from sklearn import svm # SVM\n",
    "from sklearn.linear_model import SGDClassifier # SGD\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀\n",
    "from sklearn.metrics import classification_report # 결과 요약\n",
    "from sklearn.metrics import accuracy_score # 정확성\n",
    "from sklearn.metrics import recall_score # 재현율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d727289",
   "metadata": {},
   "source": [
    "### 손글씨 분류 (0~9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0d33f",
   "metadata": {},
   "source": [
    "##### 데이터 준비 및 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ccf2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b6ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits 구성: ['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
      "feature shape: (1797, 64)\n",
      "feature 구성: 8x8 pixels\n",
      "target 구성: [0 1 2 3 4 5 6 7 8 9]\n",
      "-----------------------------------------\n",
      "미리보기\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADwklEQVR4nO3dQVFjQQBF0ekpBCABB8QBOEACSEACOMBCHERCUABxgAQc9BhIqNnQucOcs/y9eGFxq6vY9Jhz/gJ6fp/7BwDHiROixAlR4oQocULUxVeHY4wf+a/c/X6/dO/m5mbp3irPz8/Ltp6enpZtrTbnHMe+uzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ9eVzDCttNptlW6ufRzgcDsu2drvdsq23t7dlW/8jNydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROiMs8xfH5+nvsnfJuHh4dlW+/v78u2+F5uTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LGnPP04RinD/9hX/3N3+FwOCzb2u/3y7YeHx+Xbf1kc85x7LubE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVEX5/4B57Ddbpfu3d/fL9u6vr5etvXx8bFs6+XlZdlWhZsTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUWPOefpwjNOH/LXLy8tlWyufLdhsNj9ya7U55zj23c0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqItz/4BzuLq6Wrq38omEu7u7ZVvb7XbZ1v/IzQlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUmHOePhzj9OE/bLfbLd1b+X7J6+vrsq3b29tlWz/ZnHMc++7mhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtSXzzEA5+PmhChxQpQ4IUqcECVOiBInRP0BDm1UH0tiIA0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits() # 데이터 로딩\n",
    "digits_data = digits.data # 데이터 feature 변수에 담아 저장\n",
    "digits_label = digits.target # 데이터 label(target) 변수에 담아 저장\n",
    "\n",
    "# 데이터 세부사항\n",
    "print(\"digits 구성:\", dir(digits))\n",
    "print(\"feature shape:\", digits_data.shape)\n",
    "print(\"feature 구성: 8x8 pixels\")\n",
    "print(\"target 구성:\", digits.target_names)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"미리보기\")\n",
    "plt.imshow(digits.data[102].reshape(8, 8), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(\"label:\", digits_label[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8138cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b04c31",
   "metadata": {},
   "source": [
    "##### 데이터 분리 (학습용 / 시험용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00d1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c8a96",
   "metadata": {},
   "source": [
    "##### 다양한 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ebffcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사결정나무\n",
    "decision_tree = DecisionTreeClassifier(random_state = 48)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(x_test)\n",
    "\n",
    "\n",
    "# 랜덤포레스트\n",
    "random_forest = RandomForestClassifier(random_state = 25)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(x_test)\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(x_test)\n",
    "\n",
    "\n",
    "# 로지스틱 회귀\n",
    "logistic_regression = LogisticRegression(solver = 'lbfgs', max_iter = 3000)\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred_logistic_regression = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6840284",
   "metadata": {},
   "source": [
    "##### 다양한 모델 결과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "086ee703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 평가 - Accuracy\n",
      "\n",
      "1. SVM: 0.986\n",
      "2. 로지스틱 회귀: 0.978\n",
      "3. 랜덤포레스트: 0.978\n",
      "4. SGD: 0.942\n",
      "5. 의사결정나무: 0.833\n",
      "-----------------------------------------------------\n",
      "\n",
      "결과 세부사항\n",
      "\n",
      "SVM (Support Vector Machine)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.96      0.98        45\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.92      1.00      0.96        33\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       1.00      1.00      1.00        26\n",
      "           8       0.96      0.96      0.96        27\n",
      "           9       1.00      0.98      0.99        43\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "로지스틱 회귀\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.93      0.96      0.95        45\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.94      0.94      0.94        33\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       0.96      1.00      0.98        26\n",
      "           8       1.00      0.93      0.96        27\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "\n",
      "랜덤포레스트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.96      0.98        45\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.91      0.97      0.94        33\n",
      "           6       1.00      1.00      1.00        43\n",
      "           7       0.93      1.00      0.96        26\n",
      "           8       0.93      0.93      0.93        27\n",
      "           9       1.00      0.95      0.98        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.97      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "\n",
      "SGD (Stochastic Gradient Descent Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.97      0.86      0.91        36\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.89      0.94        45\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.79      1.00      0.88        33\n",
      "           6       0.98      0.98      0.98        43\n",
      "           7       0.96      1.00      0.98        26\n",
      "           8       0.74      0.93      0.82        27\n",
      "           9       1.00      0.86      0.92        43\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.95      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n",
      "\n",
      "의사결정나무\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.89      0.89      0.89        36\n",
      "           2       0.81      0.79      0.80        38\n",
      "           3       0.82      0.71      0.76        45\n",
      "           4       0.80      0.89      0.85        37\n",
      "           5       0.79      0.91      0.85        33\n",
      "           6       0.93      0.95      0.94        43\n",
      "           7       0.85      0.85      0.85        26\n",
      "           8       0.73      0.81      0.77        27\n",
      "           9       0.72      0.67      0.70        43\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.84      0.84      0.84       360\n",
      "weighted avg       0.84      0.83      0.83       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0~9 각 요소가 모두 동일한 중요도를 가지므로 별도의 우선 순위가 없음\n",
    "# 따라서, test accuracy를 기준으로 모델의 성능을 평가\n",
    "print(\"모델 성능 평가 - Accuracy\\n\")\n",
    "print(\"1. SVM:\", round(accuracy_score(y_test, y_pred_svm), 3))\n",
    "print(\"2. 로지스틱 회귀:\", round(accuracy_score(y_test, y_pred_logistic_regression), 3))\n",
    "print(\"3. 랜덤포레스트:\", round(accuracy_score(y_test, y_pred_random_forest), 3))\n",
    "print(\"4. SGD:\", round(accuracy_score(y_test, y_pred_sgd), 3))\n",
    "print(\"5. 의사결정나무:\", round(accuracy_score(y_test, y_pred_decision_tree), 3))\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"\\n결과 세부사항\")\n",
    "print(\"\\nSVM (Support Vector Machine)\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\n로지스틱 회귀\")\n",
    "print(classification_report(y_test, y_pred_logistic_regression))\n",
    "print(\"\\n랜덤포레스트\")\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"\\nSGD (Stochastic Gradient Descent Classifier)\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "print(\"\\n의사결정나무\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e6b10",
   "metadata": {},
   "source": [
    "### 와인 종류 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610da88a",
   "metadata": {},
   "source": [
    "##### 데이터 준비 및 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a029747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f55aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine 구성: ['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
      "feature shape: (178, 13)\n",
      "feature 구성: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "target 구성: ['class_0' 'class_1' 'class_2']\n",
      "-----------------------------------------\n",
      "미리보기\n",
      "feature: [1.234e+01 2.450e+00 2.460e+00 2.100e+01 9.800e+01 2.560e+00 2.110e+00\n",
      " 3.400e-01 1.310e+00 2.800e+00 8.000e-01 3.380e+00 4.380e+02]\n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine() # 데이터 로딩\n",
    "wine_data = wine.data # 데이터 feature 변수에 담아 저장\n",
    "wine_label = wine.target # 데이터 label(target) 변수에 담아 저장\n",
    "\n",
    "# 데이터 세부사항\n",
    "print(\"wine 구성:\", dir(digits))\n",
    "print(\"feature shape:\", wine_data.shape)\n",
    "print(\"feature 구성:\", wine.feature_names)\n",
    "print(\"target 구성:\", wine.target_names)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"미리보기\")\n",
    "print(\"feature:\", wine_data[102])\n",
    "print(\"label:\", wine_label[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "134d15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1147428",
   "metadata": {},
   "source": [
    "##### 데이터 분리 (학습용 / 시험용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e08a3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size = 0.2, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031562e",
   "metadata": {},
   "source": [
    "##### 다양한 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfb14d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사결정나무\n",
    "decision_tree = DecisionTreeClassifier(random_state = 18)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(x_test)\n",
    "\n",
    "\n",
    "# 랜덤포레스트\n",
    "random_forest = RandomForestClassifier(random_state = 41)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(x_test)\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(x_test)\n",
    "\n",
    "\n",
    "# 로지스틱 회귀\n",
    "logistic_regression = LogisticRegression(solver = 'lbfgs', max_iter = 3000)\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred_logistic_regression = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07cbc7",
   "metadata": {},
   "source": [
    "##### 다양한 모델 결과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f9ef6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 평가 - Accuracy\n",
      "\n",
      "1. 랜덤포레스트: 1.0\n",
      "2. 로지스틱 회귀: 0.944\n",
      "3. 의사결정나무: 0.917\n",
      "4. SVM: 0.778\n",
      "5. SGD: 0.75\n",
      "-----------------------------------------------------\n",
      "\n",
      "결과 세부사항\n",
      "\n",
      "랜덤포레스트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "로지스틱 회귀\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.92      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "의사결정나무\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.93      0.88      0.90        16\n",
      "           2       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.90      0.90      0.90        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "\n",
      "SVM (Support Vector Machine)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        14\n",
      "           1       0.92      0.69      0.79        16\n",
      "           2       0.45      0.83      0.59         6\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.76      0.79      0.75        36\n",
      "weighted avg       0.84      0.78      0.79        36\n",
      "\n",
      "\n",
      "SGD (Stochastic Gradient Descent Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        14\n",
      "           1       0.78      0.88      0.82        16\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.50      0.60      0.55        36\n",
      "weighted avg       0.63      0.75      0.68        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 와인의 세 종류가 모두 동일한 중요도를 가지므로 별도의 우선 순위가 없음\n",
    "# 따라서, test accuracy를 기준으로 모델의 성능을 평가\n",
    "print(\"모델 성능 평가 - Accuracy\\n\")\n",
    "print(\"1. 랜덤포레스트:\", round(accuracy_score(y_test, y_pred_random_forest), 3))\n",
    "print(\"2. 로지스틱 회귀:\", round(accuracy_score(y_test, y_pred_logistic_regression), 3))\n",
    "print(\"3. 의사결정나무:\", round(accuracy_score(y_test, y_pred_decision_tree), 3))\n",
    "print(\"4. SVM:\", round(accuracy_score(y_test, y_pred_svm), 3))\n",
    "print(\"5. SGD:\", round(accuracy_score(y_test, y_pred_sgd), 3))\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"\\n결과 세부사항\")\n",
    "print(\"\\n랜덤포레스트\")\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"\\n로지스틱 회귀\")\n",
    "print(classification_report(y_test, y_pred_logistic_regression))\n",
    "print(\"\\n의사결정나무\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "print(\"\\nSVM (Support Vector Machine)\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nSGD (Stochastic Gradient Descent Classifier)\")\n",
    "print(classification_report(y_test, y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033f26f",
   "metadata": {},
   "source": [
    "### 유방암 진단 (악성, 양성)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d54a5",
   "metadata": {},
   "source": [
    "##### 데이터 준비 및 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52159278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c1cc4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast cancer 구성: ['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
      "feature shape: (569, 30)\n",
      "feature 구성: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "target 구성: ['malignant' 'benign']\n",
      "-----------------------------------------\n",
      "미리보기\n",
      "feature: [1.218e+01 2.052e+01 7.722e+01 4.587e+02 8.013e-02 4.038e-02 2.383e-02\n",
      " 1.770e-02 1.739e-01 5.677e-02 1.924e-01 1.571e+00 1.183e+00 1.468e+01\n",
      " 5.080e-03 6.098e-03 1.069e-02 6.797e-03 1.447e-02 1.532e-03 1.334e+01\n",
      " 3.284e+01 8.458e+01 5.478e+02 1.123e-01 8.862e-02 1.145e-01 7.431e-02\n",
      " 2.694e-01 6.878e-02]\n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = load_breast_cancer() # 데이터 로딩\n",
    "breast_cancer_data = breast_cancer.data # 데이터 feature 변수에 담아 저장\n",
    "breast_cancer_label = breast_cancer.target # 데이터 label(target) 변수에 담아 저장\n",
    "\n",
    "# 데이터 세부사항\n",
    "print(\"breast cancer 구성:\", dir(breast_cancer))\n",
    "print(\"feature shape:\", breast_cancer_data.shape)\n",
    "print(\"feature 구성:\", breast_cancer.feature_names)\n",
    "print(\"target 구성:\", breast_cancer.target_names)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"미리보기\")\n",
    "print(\"feature:\", breast_cancer_data[102])\n",
    "print(\"label:\", breast_cancer_label[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b9db2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638335da",
   "metadata": {},
   "source": [
    "##### 데이터 분리 (학습용 / 시험용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddc84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43254c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사결정나무\n",
    "decision_tree = DecisionTreeClassifier(random_state = 36)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(x_test)\n",
    "\n",
    "\n",
    "# 랜덤포레스트\n",
    "random_forest = RandomForestClassifier(random_state = 11)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(x_test)\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(x_test)\n",
    "\n",
    "\n",
    "# 로지스틱 회귀\n",
    "logistic_regression = LogisticRegression(solver = 'lbfgs', max_iter = 3000)\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred_logistic_regression = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e586a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 평가 - Recall\n",
      "\n",
      "1. 로지스틱 회귀: 0.949\n",
      "2. SVM: 0.936\n",
      "3. 랜덤포레스트: 0.897\n",
      "4. 의사결정나무: 0.859\n",
      "5. SGD: 0.551\n",
      "-----------------------------------------------------\n",
      "\n",
      "결과 세부사항\n",
      "\n",
      "로지스틱 회귀\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87        36\n",
      "           1       0.94      0.95      0.94        78\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.90      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "\n",
      "SVM (Support Vector Machine)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79        36\n",
      "           1       0.89      0.94      0.91        78\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.84      0.85       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "\n",
      "랜덤포레스트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89        36\n",
      "           1       0.99      0.90      0.94        78\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.90      0.93      0.91       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "\n",
      "의사결정나무\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83        36\n",
      "           1       0.96      0.86      0.91        78\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.85      0.89      0.87       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "\n",
      "SGD (Stochastic Gradient Descent Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.97      0.66        36\n",
      "           1       0.98      0.55      0.70        78\n",
      "\n",
      "    accuracy                           0.68       114\n",
      "   macro avg       0.74      0.76      0.68       114\n",
      "weighted avg       0.83      0.68      0.69       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 악성 환자를 양성 환자로 판단하는 것은 치명적이므로 FN의 최소화가 최우선\n",
    " # 따라서, 재현율(recall)을 기준으로 평가 [positve = 악성, negative = 양성]\n",
    "print(\"모델 성능 평가 - Recall\\n\")\n",
    "print(\"1. 로지스틱 회귀:\", round(recall_score(y_test, y_pred_logistic_regression, labels = [1, 0]), 3))\n",
    "print(\"2. SVM:\", round(recall_score(y_test, y_pred_svm, labels = [1, 0]), 3))\n",
    "print(\"3. 랜덤포레스트:\", round(recall_score(y_test, y_pred_random_forest, labels = [1, 0]), 3))\n",
    "print(\"4. 의사결정나무:\", round(recall_score(y_test, y_pred_decision_tree, labels = [1, 0]), 3))\n",
    "print(\"5. SGD:\", round(recall_score(y_test, y_pred_sgd, labels = [1, 0]), 3))\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"\\n결과 세부사항\")\n",
    "print(\"\\n로지스틱 회귀\")\n",
    "print(classification_report(y_test, y_pred_logistic_regression))\n",
    "print(\"\\nSVM (Support Vector Machine)\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\n랜덤포레스트\")\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(\"\\n의사결정나무\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "print(\"\\nSGD (Stochastic Gradient Descent Classifier)\")\n",
    "print(classification_report(y_test, y_pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71081",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93910f1f",
   "metadata": {},
   "source": [
    "## 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f3e1b",
   "metadata": {},
   "source": [
    "- 손글씨 분류 (0~9)<br/>\n",
    "<br/>\n",
    "데이터가 고르게 있는가?<br/>\n",
    "모델 종류별 데이터 분석 결과 세부사항을 보면 데이터가 얼마나 치중되어 있는 지 알 수 있다.<br/>\n",
    "0부터 9까지의 데이터는 각각 대략 35개이며, 데이터가 가장 작은 요소가 26개의 데이터로 데이터가 가장 많은 요소가 45개의 데이터로 구성되어 있다.<br/>\n",
    "나는 이러한 특정 데이터가 특별히 치중되어 있지 않다고 판단, 즉 데이터가 고르게 있다고 보았다.<br/>\n",
    "<br/>\n",
    "우선순위는!<br/>\n",
    "만약 0을 1로 보는 것이 1을 0으로 보는 것보다 심각한 결과를 초래한다면 0을 1로 잘못 보는 것에 우선 순위를 둘 것이다.<br/>\n",
    "하지만 이 모델의 쓰임이 명확하지 않으므로 오직 정확성(test accuracy)을 기준으로 모델의 성능을 평가한다.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223e233",
   "metadata": {},
   "source": [
    "- 와인 종류 분류<br/>\n",
    "<br/>\n",
    "데이터는 고르게 있는가?<br/>\n",
    "와인 종류는 세가지 0, 1, 2가 있다.<br/>\n",
    "와인 종류를 분류하는 분석 데이터는 2가 0과 1의 데이터 개수의 절반 이하로 꽤나 적은 것으로 평가된다.<br/>\n",
    "즉, 데이터가 고르게 있지 않다고 보았다.<br/>\n",
    "이런 데이터 분포의 문제점은 만약 모델이 2를 아예 배제하고 0과 1만 판별할 수 있다고 할 지라도 꽤나 정확도가 높게 평가될 수 있다는 것이다.<br/>\n",
    "하지만 세부사항의 precision과 recall, accuracy 세 지표를 비교하면 대체로 precision과 recall이 높은 모델이 accuracy도 높은 것으로 보인다.<br/>\n",
    "이 분석 결과의 쓰임이 분석 단계에서 명확하지 않으므로 데이터의 분포가 고르지 않은 것은 성능 평가에 영향을 주지 않는 것으로 간주한다.<br/>\n",
    "<br/>\n",
    "우선 순위는!<br/>\n",
    "이전 손글씨 분류와 마찬가지로 0, 1, 2 중 특별한 우선 순위가 없는 것으로 보인다.<br/>\n",
    "만약 1이 인기 모델이므로 1을 잘못 판단하는 것이 더 많은 사용자에게 혼란을 준다면, 1을 우선 순위로 모델의 성능을 평가해야할 것이다.<br/>\n",
    "하지만 이 모델의 쓰임이 명확하지 않으므로 오직 정확성(test accuracy)을 기준으로 모델의 성능을 평가한다.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b92a3",
   "metadata": {},
   "source": [
    "- 유방암 진단 (악성, 양성)<br/>\n",
    "<br/>\n",
    "데이터는 고르게 있는가?<br/>\n",
    "위 데이터 정보를 확인하면 0이 악성(malignant)이고, 1이 양성(benign)이다.<br/>\n",
    "악성 종양의 데이터는 양성 종양의 데이터보다 적다.<br/>\n",
    "<br/>\n",
    "우선 순위는!<br/>\n",
    "이전 분석과 다르게 유방암 진단의 경우 악성 종양을 양성 종양으로 판단하는 것은 환자에게 치명적일 것이라는 예상이 가능하다.<br/>\n",
    "따라서 악성 종양을 양성 종양으로 판단하는 오류를 최소화하는 모델을 우선 순위에 둘 필요가 있다.<br/>\n",
    "재현율(recall)은 실제 악성 종양 대비 악성 종양을 잘 판단한 비율이다.<br/>\n",
    "따라서 이 분석에서 모델 성능은 재현율을 기준으로 평가한다.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c0c37",
   "metadata": {},
   "source": [
    "이러한 분석을 토대로 모델의 성능을 평가하고 우선 순위를 두었지만, 사실은 모델의 성능 평가 기준으로 삼은 정확성(test accuracy)과 재현율(recall)은 random-state에 따라 변하는 것을 확인하였다.<br/>\n",
    "따라서 실무를 할 때는 더 많은 데이터를 토대로, 훈련용 데이터(train data)와 검증용 데이터(validation data)를 여러번 나누어 학습하고, 모델의 성능을 평가하는 교차검증 기법을 사용해야 할 것이다.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd55a6b",
   "metadata": {},
   "source": [
    "## 학습 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53a4b8",
   "metadata": {},
   "source": [
    "- Confused Matrix (오차 행렬)<br/>\n",
    "<br/>\n",
    "학습 이진 분류 모델을 평가하는 지표이다.<br/>\n",
    "<br/>\n",
    "다음 네가지 유형이 있다.<br/>\n",
    "TP : 예측이 맞다, Positve 예측, Positive 사실<br/>\n",
    "TN : 예측이 맞다, Negative 예측, Negative 사실<br/>\n",
    "FP : 예측이 틀리다, Positve 예측, Negative 사실<br/>\n",
    "FN : 예측이 틀리다, Negative 예측, Positve 사실<br/>\n",
    "<br/>\n",
    "유형은 두개의 알파벳 형식이다.<br/>\n",
    "앞 글자(T or F)는 예측이 맞았는 지 틀렸는 지 여부이다. T는 예측이 맞은 것이고, F는 예측이 틀린 것이다.<br/>\n",
    "뒷 글자(P or N)은 예측한 내용이다. P는 Positive로 예측한 것이고, N은 Negative로 예측한 것이다.<br/>\n",
    "<br/>\n",
    "대개 Positive는 1로, Negative는 0으로 학습한다. 이는 True / False 개념과도 상통하기 때문에 이해가 용이하지만 실제 분석 환경에서는 헷갈릴 수 있다.<br/>\n",
    "왜냐하면 항상 1이 Positive이고, 0이 Negative이지 않기 때문이다. 상황에 따라 1은 Negative 0은 Positive로, 양성은 Negative 음성은 Positive로 여길 수도 있다.<br/>\n",
    "따라서 오차행렬을 사용할 때는 Positive와 Negative 기준이 절대적이지 않다는 점에 유의해야 한다.<br/>\n",
    "skleran은 label을 이용하여 어떤 관점에 볼 건 지 정해줄 수 있으니 명확하게 하는 편이 좋겠다.<br/>\n",
    "<br/>\n",
    "[Scikit-learn confusion matrix, stackoverflow, (2022.01.06)](https://stackoverflow.com/questions/35178590/scikit-learn-confusion-matrix)\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df6536",
   "metadata": {},
   "source": [
    "- Convergence warning<br/>\n",
    "<br/>\n",
    "Scikit learn 업데이트 이후, 로지스틱 회귀를 사용할 경우 이와 같은 경고 메시지가 나온다.<br/>\n",
    "기본 최대치인 100번 반복 수행했지만 결과물을 도출하지 못했다는 뜻으로 반복 회수 최대치를 늘려주면 해결할 수 있다.<br/>\n",
    "아래 글을 참조하였고, 팀원의 도움을 받았다.<br/>\n",
    "<br/>\n",
    "[Q. logistic regression에서 convergence warning, Inflearn, (2022.01.06)](https://www.inflearn.com/questions/62388)\n",
    "<br/>\n",
    "<br/>\n",
    "```\n",
    "model_name = LogisticRegression() # 이전 (max_iter = 100)\n",
    "model_name = LogisticRegression(solver = 'lbfgs', max_iter = 3000) # 변경 후\n",
    "```\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f480ef2",
   "metadata": {},
   "source": [
    "#### 사족"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4dda2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "*두번째 데이터 분석 프로젝트였다.* <br/>\n",
    "*여러 모델을 학습해보고, 도출한 결과를 바탕으로 모델을 평가하는 유익한 경험이었다.* <br/>\n",
    "*scikit learn을 사용하니 코드 자체는 어렵지 않았다.* <br/>\n",
    "*그래서 이번 프로젝트를 진행할 땐, 보는 사람 입장에서 더 쉽게 이해할 수 있도록 코드와 주석을 작성하는데 초점을 두었다.* <br/>\n",
    "*또한 데이터에 대한 설명부, 모델링 결과부를 한눈에 보이도록 표현하고자 했다.* <br/>\n",
    "*파이썬으로 구현할 수 있는 테이블 출력도 생각을 해봤지만 scikit learn의 활용과 관련성이 떨어지는 듯해 하지 않았다.* <br/>\n",
    "*파이썬에 더 익숙해지면 더 깔끔하게 출력하도록 해야겠다.* <br/>\n",
    "<br/>\n",
    "*팀원과 함께 scikit learn에 대해 토론하면서 이런 논제가 나왔다.* <br/>\n",
    "*좋은 API를 잘 활용하는 게 좋다! vs 원리를 이해해야 한다!* <br/>\n",
    "*전자의 의견은 이렇다. 급속도로 발전하는 요즘, 모든 신기술을 깊이 이해할 수는 없다. 이를 활용하는 것 또한 스킬, 새로 나오는 것을 잘 받아들이고 효율적으로 사용하자.* <br/>\n",
    "*후자의 의견은 이렇다. 이번 기회에 좋은 라이브러리를 알게 되고 쉽게 사용했지만, 충분한 학습 뒤에는 직접 하나하나 구현해 볼 필요가 있다. 사용 뿐 아니라 깊이 있는 이해가 필요하다.* <br/>\n",
    "*모두 일리가 있어 고민을 하고 있던 차에 퍼실님께서 첨언을 주셨다.* <br/>\n",
    "*처음 공부를 시작할 때 이런 라이브러리를 사용해서 경험을 쌓는 것은 좋다. 하지만 차후에 보다 효율적으로 상황에 최적하게 사용하려면 원리를 이해해야 한다.* <br/>\n",
    "*이번 노드에서 나오는 다양한 이론들, 이런저런 글들을 독해해가며 어느정도는 이해했다고 생각한다.* <br/>\n",
    "*하지만 필요한 상황에서 효율적으로 사용할 수 있으려면 깊이 있는 이해와 많은 경험이 필요할 것 같다는 생각이다.* <br/>\n",
    "<br/>\n",
    "*Exploration에 이어서 바로 다음 날 Fundamental 학습으로 scikit learn과 다양한 머신러닝 모델에 대해 공부했다.* <br/>\n",
    "*너무나도 많은 알고리즘이 있다. 모두 기억하고 있다가 필요할 때 적절히 적용하려면 모델에 대한 복습이 더 필요할 것 같다.* <br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
